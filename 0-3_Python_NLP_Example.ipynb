{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 간단한 자연어 분석/처리 예제\n",
        "\n"
      ],
      "metadata": {
        "id": "Od9sDI9apHxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# colab 환경 기본 설치된 패키지\n",
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fz2leM6oe1TI",
        "outputId": "a5918bd7-0c9e-43d0-fe77-6b02c32dd0ae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "vWC8H8S5OPEr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIirnhiLehN4",
        "outputId": "a3b8c197-ed32-4441-e7d3-0328024d241f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      text     lemma       pos       tag       dep     shape  is_alpha   is_stop\n",
            "================================================================================\n",
            "      When      when     SCONJ       WRB    advmod      Xxxx      True      True\n",
            " Sebastian sebastian       ADJ        JJ      amod     Xxxxx      True     False\n",
            "     Thrun     Thrun     PROPN       NNP     nsubj     Xxxxx      True     False\n",
            "   started     start      VERB       VBD     advcl      xxxx      True     False\n",
            "   working      work      VERB       VBG     xcomp      xxxx      True     False\n",
            "        on        on       ADP        IN      prep        xx      True      True\n",
            "      self      self      NOUN        NN  npadvmod      xxxx      True     False\n",
            "         -         -     PUNCT      HYPH     punct         -     False     False\n",
            "   driving     drive      VERB       VBG      amod      xxxx      True     False\n",
            "      cars       car      NOUN       NNS      pobj      xxxx      True     False\n",
            "        at        at       ADP        IN      prep        xx      True      True\n",
            "    Google    Google     PROPN       NNP      pobj     Xxxxx      True     False\n",
            "        in        in       ADP        IN      prep        xx      True      True\n",
            "      2007      2007       NUM        CD      pobj      dddd     False     False\n",
            "         ,         ,     PUNCT         ,     punct         ,     False     False\n",
            "       few       few       ADJ        JJ      amod       xxx      True      True\n",
            "    people    people      NOUN       NNS     nsubj      xxxx      True     False\n",
            "   outside   outside       ADP        IN      prep      xxxx      True     False\n",
            "        of        of       ADP        IN      prep        xx      True      True\n",
            "       the       the       DET        DT       det       xxx      True      True\n",
            "   company   company      NOUN        NN      pobj      xxxx      True     False\n",
            "      took      take      VERB       VBD      ROOT      xxxx      True     False\n",
            "       him        he      PRON       PRP      dobj       xxx      True      True\n"
          ]
        }
      ],
      "source": [
        "# load model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\"\"\"\n",
        "문장을 구성하는 요소들을 쪼개 token을 만들고 token에는 다음과 같은 변수들이 정의된다.\n",
        "\n",
        "text - 원본 text\n",
        "lemma - 단어의 기본 형태\n",
        "pos - 간단한 POS(part-of-speech) 태그\n",
        "tag - 자세한 POS 태그\n",
        "dep - 구문적 종속성(토큰 간의 관계)\n",
        "shape - 단어의 모양(대문자, 구두점, 숫자)\n",
        "is_alpha - 토큰이 alpha만 있는가(True/False)\n",
        "is_stop - is, the, of, on, at등 내용적 의미가 없는 단어인가(True/False)\n",
        "\"\"\"\n",
        "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
        "        \"Google in 2007, few people outside of the company took him \")\n",
        "doc = nlp(text)\n",
        "\n",
        "str_format = \"{:>10}\"*8\n",
        "print(str_format.format(\"text\", \"lemma\", \"pos\", \"tag\", \"dep\", \"shape\", \"is_alpha\", \"is_stop\"))\n",
        "print(\"==\"*40)\n",
        "for token in doc:\n",
        "  print(str_format.format(token.text, token.lemma_, token.pos_, token.tag_,\n",
        "                            token.dep_, token.shape_, str(token.is_alpha), str(token.is_stop)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "docs.ents - 의미를 이해한 토큰을 반환한다.(사람인지, 조직인지 날짜인지 등)\n",
        "\"\"\"\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-j1MZElmIUl",
        "outputId": "b091a9c7-a007-4e49-d94a-cf6de816d672"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sebastian Thrun PERSON\n",
            "Google ORG\n",
            "2007 DATE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "CountVectorizer\n",
        "텍스트 데이터를 분석할 때 사용할 수 있는 전처리 중 하나이다.\n",
        "텍스트를 단어들의 카운트로 벡터화한다.\n",
        "\"\"\"\n",
        "sample = [\n",
        "  \"The drug Aspirin inhibits the protein COX-2.\",\n",
        "  \"The drug Ibuprofen targets the protein COX-1.\",\n",
        "  \"The drug Corona kill the protein COX-1.\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorized_sample = vectorizer.fit_transform(sample)\n",
        "print(vectorized_sample.toarray())\n",
        "\n",
        "# 각 단어가 몇번째 열에 해당하는지 볼 수 있다.\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSfmXKgJMgdw",
        "outputId": "33f16dcd-15c9-4ab6-9483-77c97bf842ec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 1 1 0 1 0 1 0 2]\n",
            " [0 0 1 1 1 0 0 1 1 2]\n",
            " [0 1 1 1 0 0 1 1 0 2]]\n",
            "{'the': 9, 'drug': 3, 'aspirin': 0, 'inhibits': 5, 'protein': 7, 'cox': 2, 'ibuprofen': 4, 'targets': 8, 'corona': 1, 'kill': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "※ 머신러닝 알고리즘의 자세한 내용은 교재 뒤편에 등장합니다. 가볍게 지나가주세요.\n",
        "\n",
        "vectorizer한 텍스트는 다음과 같이 모델 학습에 사용될 수 있다.\n",
        "train_data의 3가지 문장과 라벨은 아래와 같습니다.\n",
        "\n",
        "\"아스피린이라는 약물은 COX-2 단백질을 억제합니다.\", 억제한다.\n",
        "\"이부프로펜이라는 약물은 COX-1 단백질을 강화합니다.\", 강화한다.\n",
        "\"코로나라는 약물은 박테리아 COX-1을 약화시킵니다.\", 약화시킨다.\n",
        "\n",
        "3가지 문장을 학습하고\n",
        "\"코로나는 COX-2 단백질에 영향을 미칩니다.\" 라는 문장을 predict하면 \"약화시킨다\" 라는 label로 분류합니다.\n",
        "\"\"\"\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "label = [\"inhibits\", \"strengthens\", \"weaken\"]\n",
        "train_data = [\n",
        "    \"The drug Aspirin inhibits the protein COX-2.\",\n",
        "    \"The drug ibuprofen strengthens the protein COX-1.\",\n",
        "    \"The drug Corona weaken the bacteria COX-1.\"\n",
        "]\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorized_train_data = vectorizer.fit_transform(train_data)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(vectorized_train_data, label)\n",
        "\n",
        "vectorized_test_data = vectorizer.transform([\"The corona affects the protein COX-2.\"])\n",
        "result = model.predict(vectorized_test_data)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9VRPb5gpjSn",
        "outputId": "64250b04-cacc-4550-c029-5c316ef4b480"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['weaken']\n"
          ]
        }
      ]
    }
  ]
}